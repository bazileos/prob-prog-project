{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> File description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current script tackles only the **Bayesian Inference** part of the case study. The code corresponding to the DRL part, has been removed for readability and understanding purposes. In case of any questions regarding the script and the physical problem in general contact the author. More information on the case study can be found in the fifth (5th) chapter of this [thesis report](https://repository.tudelft.nl/islandora/object/uuid%3Ad8d0ff11-077a-471b-8939-e1a0496d02dd?collection=education)\n",
    "\n",
    "---\n",
    "\n",
    "Author: Christos Lathourakis<br>\n",
    "email: xristosl0610@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vUBrcn9bBF4"
   },
   "source": [
    "<h4> Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24389,
     "status": "ok",
     "timestamp": 1654664799576,
     "user": {
      "displayName": "Christos Lathourakis",
      "userId": "10659327587245285172"
     },
     "user_tz": -120
    },
    "id": "j_e-XMyZbBGD",
    "outputId": "fb7e1316-424c-4771-8220-3252b13a1f60"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "\n",
    "from scipy import stats\n",
    "import scipy as sp\n",
    "\n",
    "from math import sqrt as mathsqrt\n",
    "from math import log as mathlog\n",
    "\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "\n",
    "import sys\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger('pymc3')\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from pprint import pprint as pp\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_Ee5HlkbBGO"
   },
   "source": [
    "<h4> FEM dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is assumed that the needed `feastruct` directory is located in the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 6118,
     "status": "ok",
     "timestamp": 1654664809456,
     "user": {
      "displayName": "Christos Lathourakis",
      "userId": "10659327587245285172"
     },
     "user_tz": -120
    },
    "id": "mm6nXykVbBGP"
   },
   "outputs": [],
   "source": [
    "from feastruct.pre.material import Steel\n",
    "from feastruct.pre.section import Section\n",
    "import feastruct.fea.cases as cases\n",
    "from feastruct.fea.frame_analysis import FrameAnalysis2D\n",
    "from feastruct.solvers.naturalfrequency import NaturalFrequency\n",
    "from feastruct.solvers.linstatic import LinearStatic\n",
    "from feastruct.solvers.feasolve import SolverSettings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5LSNwCY51LF4"
   },
   "source": [
    "<h4> FORM dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is assumed that the needed `FORM` directory is located in the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 988,
     "status": "ok",
     "timestamp": 1654664812942,
     "user": {
      "displayName": "Christos Lathourakis",
      "userId": "10659327587245285172"
     },
     "user_tz": -120
    },
    "id": "jpmuom_c1OUc"
   },
   "outputs": [],
   "source": [
    "from FORM.ERANataf import ERANataf\n",
    "from FORM.ERADist import ERADist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgHGOLGbbBGS"
   },
   "source": [
    "<h4> Finite Element Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 562,
     "status": "ok",
     "timestamp": 1654664813824,
     "user": {
      "displayName": "Christos Lathourakis",
      "userId": "10659327587245285172"
     },
     "user_tz": -120
    },
    "id": "QZkcLhzGbBGU"
   },
   "outputs": [],
   "source": [
    "class FEModel():\n",
    "    def __init__(self, L=4, storeys=3, qd=3.6):\n",
    "        self.L = L\n",
    "        self.numStoreys = storeys\n",
    "        self.numCols = 2 * self.numStoreys\n",
    "        self.numModes = self.numStoreys\n",
    "\n",
    "        self.qd = qd\n",
    "\n",
    "        self.crosSecs = {'beam' : {'name' : 'IPE220',\n",
    "                                   'tf' : 0.0092, \n",
    "                                   'bf' : 0.110, \n",
    "                                   'hw' : 0.2016, \n",
    "                                   'tw' : 0.0059},\n",
    "                         'col' : {'name' : 'HEA300',\n",
    "                                  'tf' : 0.014, \n",
    "                                  'bf' : 0.300, \n",
    "                                  'hw' : 0.262, \n",
    "                                  'tw' : 0.0085}}\n",
    "        # Define the cross-sections\n",
    "        for cs in ('beam', 'col'):\n",
    "            self.crosSecs[cs]['A0'] = 2 * self.crosSecs[cs]['tf'] * self.crosSecs[cs]['bf'] + self.crosSecs[cs]['tw'] * self.crosSecs[cs]['hw']\n",
    "            self.crosSecs[cs]['I0'] = 2 * (self.crosSecs[cs]['bf'] * self.crosSecs[cs]['tf'] ** 3 / 12 + \\\n",
    "                                self.crosSecs[cs]['bf'] * self.crosSecs[cs]['tf'] * (self.crosSecs[cs]['hw'] / 2 + self.crosSecs[cs]['tf'] / 2) ** 2) + \\\n",
    "                                self.crosSecs[cs]['tw'] * self.crosSecs[cs]['hw'] ** 3 / 12\n",
    "        # Create the node coordinates\n",
    "        self.nodeCoords = [*[(0., k * self.L) for k in range(self.numStoreys + 1)],\n",
    "                    *[(self.L, k * self.L) for k in range(self.numStoreys + 1)]]\n",
    "\n",
    "        self.elemInfo = [{'start' : k, 'end' : k + 1, 'area' : self.crosSecs['col']['A0'], 'ixx' : self.crosSecs['col']['I0']} for k in range(self.numCols + 1) if k != self.numStoreys]\n",
    "\n",
    "        self.elemInfo.extend([{'start' : k, 'end' : k + (self.numStoreys + 1), 'area' : self.crosSecs['beam']['A0'], 'ixx' : self.crosSecs['beam']['I0']} for k in [c for c in range(1, self.numStoreys+1)]])\n",
    "\n",
    "        # Copy the element's info in order to change the damages in-place \n",
    "        self.defaultElemInfo = self.elemInfo.copy()\n",
    "\n",
    "        # Store the Boundary Conditions' info\n",
    "        self.bcInfo = {0 : (0, 1, 5),\n",
    "                self.numStoreys + 1 : (0, 1, 5)}\n",
    "\n",
    "        self.analysis = self._create_analysis(default=True)\n",
    "\n",
    "        # Calculate the equivalent points loads applied to the nodes, to replace the triangular load\n",
    "        elemDistLoadVals = {k : {\"startLoad\" : self.qd * self.analysis.elements[k].nodes[0].y / (3 * L),\n",
    "                            \"endLoad\" : self.qd * self.analysis.elements[k].nodes[1].y / (3 * L)} for k in range(3)}\n",
    "\n",
    "        elemPointForces = {k : {'start' : elemDistLoadVals[k]['startLoad'] * self.L / 3 + elemDistLoadVals[k]['endLoad'] * self.L / 6,\n",
    "                            'end' : elemDistLoadVals[k]['startLoad'] * self.L / 6 + elemDistLoadVals[k]['endLoad'] * self.L / 3} for k in range(3)}\n",
    "\n",
    "        self.nodeForces = [elemPointForces[0]['start'], *[elemPointForces[k]['end'] + elemPointForces[k+1]['start'] for k in range(2)], elemPointForces[2]['end']]\n",
    "\n",
    "        # Assign the Boundary Conditions\n",
    "        self.freedom_case = cases.FreedomCase()\n",
    "\n",
    "        for nodeId, constDofs in self.bcInfo.items():\n",
    "            for dofId in constDofs:\n",
    "                self.freedom_case.add_nodal_support(node=self.analysis.nodes[nodeId], val=0, dof=dofId)\n",
    "\n",
    "        # Assign the applied loads\n",
    "        self.load_case = cases.LoadCase()\n",
    "\n",
    "        for nodeId, loadVal in enumerate(self.nodeForces):\n",
    "            self.load_case.add_nodal_load(node=self.analysis.nodes[nodeId], val=loadVal * 1e3, dof=0)\n",
    "\n",
    "        # Set up the analysis case (BCs and Loads)\n",
    "        self.analysis_case = cases.AnalysisCase(freedom_case=self.freedom_case, load_case=self.load_case)\n",
    "\n",
    "        # Set up the settings for eigen- and linear static analysis\n",
    "        self.settings = SolverSettings()\n",
    "        self.settings.natural_frequency.time_info = False\n",
    "        self.settings.linear_static.time_info = False\n",
    "        self.settings.natural_frequency.num_modes = self.numModes\n",
    "\n",
    "        eigSolver = NaturalFrequency(analysis=self.analysis, analysis_cases=[self.analysis_case], solver_settings=self.settings)\n",
    "        linStatSolver = LinearStatic(analysis=self.analysis, analysis_cases=[self.analysis_case], solver_settings=self.settings)\n",
    "\n",
    "        # Run the default analyses\n",
    "        eigSolver.solve()\n",
    "        linStatSolver.solve()\n",
    "\n",
    "        self.undamagedEigmodes = [self.analysis.elements[0].get_frequency_results(analysis_case=self.analysis_case, frequency_mode=k)[0] for k in range(self.numModes)]\n",
    "        self.undamagedModalDispls = np.array([[self.analysis.nodes[k].get_dofs([True, True, False, False, False, True])[0].get_frequency_mode(self.analysis_case, kk)[1] for k in [1, 2, 3, 5, 6, 7]] for kk in (0, 1, 2)])\n",
    "        self.undamagedDrift = self.analysis.nodes[self.numStoreys].get_displacements(analysis_case=self.analysis_case)[0]\n",
    "        \n",
    "    def _create_analysis(self, mat=Steel(), default=False):\n",
    "        # create 2d frame analysis object\n",
    "        analysis = FrameAnalysis2D()\n",
    "\n",
    "        # create nodes\n",
    "        for coords in self.nodeCoords:\n",
    "            analysis.create_node(coords=coords)\n",
    "\n",
    "        elInfo = self.defaultElemInfo if default else self.elemInfo\n",
    "        # create elements\n",
    "        for elem in elInfo:\n",
    "            analysis.create_element(\n",
    "                el_type=\"EB2-2D\",\n",
    "                nodes=(analysis.nodes[elem['start']], analysis.nodes[elem['end']]),\n",
    "                material=mat,\n",
    "                section=Section(area=elem['area'], ixx=elem['ixx']))\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def eigen_analysis(self, damages):\n",
    "        for k, dam in enumerate(damages):\n",
    "            self.elemInfo[k]['area'], self.elemInfo[k]['ixx'], _ = self._calc_reduced_props(dam, self.crosSecs['col'])\n",
    "    \n",
    "            self.analysis = self._create_analysis()\n",
    "\n",
    "        solver = NaturalFrequency(analysis=self.analysis, analysis_cases=[self.analysis_case], solver_settings=self.settings)\n",
    "\n",
    "        solver.solve()\n",
    "\n",
    "        return np.array([self.analysis.nodes[k].get_dofs([True, True, False, False, False, True])[0].get_frequency_mode(self.analysis_case, 0)[1] for k in [1, 2, 3, 5, 6, 7]])\n",
    "\n",
    "    def linear_static_analysis(self, damages, node=3, dof=0):\n",
    "        for k, dam in enumerate(damages):\n",
    "            self.elemInfo[k]['area'], self.elemInfo[k]['ixx'], _ = self._calc_reduced_props(dam, self.crosSecs['col'])\n",
    "    \n",
    "            self.analysis = self._create_analysis()\n",
    "\n",
    "\n",
    "        solver = LinearStatic(analysis=self.analysis, analysis_cases=[self.analysis_case], solver_settings=self.settings)\n",
    "\n",
    "        solver.solve()\n",
    "\n",
    "        # return the displacement along dof, for the input node\n",
    "        return self.analysis.nodes[node].get_displacements(analysis_case=self.analysis_case)[dof]\n",
    "    \n",
    "    # Misc functions\n",
    "    def _calc_reduced_props(self, ddet, crosSec):\n",
    "        ddet = np.clip(ddet, a_min=0., a_max=0.999)\n",
    "\n",
    "        A = 4.0\n",
    "        B = 2 * (crosSec['tw'] - crosSec['hw'] - 2 * crosSec['tf'] - 2 * crosSec['bf'])\n",
    "        C = ddet * crosSec['A0']\n",
    "\n",
    "        c = (-B - np.sqrt(B ** 2 - 4 * A * C)) / (2 * A)\n",
    "\n",
    "        A_ = 2 * (crosSec['tf'] - 2 * c) * (crosSec['bf'] - 2 * c) + (crosSec['tw'] - 2 * c) * (crosSec['hw'] + 2 * c)\n",
    "\n",
    "        I_ = (\n",
    "            2\n",
    "            * (\n",
    "                (crosSec['bf'] - 2 * c) * (crosSec['tf'] - 2 * c) ** 3 / 12\n",
    "                + (crosSec['bf'] - 2 * c) * (crosSec['tf'] - 2 * c) * (crosSec['hw'] / 2 + crosSec['tf'] / 2) ** 2\n",
    "            )\n",
    "            + (crosSec['tw'] - 2 * c) * (crosSec['hw'] + 2 * c) ** 3 / 12\n",
    "        )\n",
    "\n",
    "        return A_, I_, c\n",
    "\n",
    "    def _two_point_dist(self, p1, p2):\n",
    "        return np.sqrt(np.sum((np.array(p1.coords) - np.array(p2.coords)) ** 2))\n",
    "\n",
    "    def _element_length(self, elem):\n",
    "        return self._two_point_dist(elem.nodes[0], elem.nodes[1])\n",
    "\n",
    "    def _element_mass(self, elem):\n",
    "        return elem.material.rho * elem.section.area * self._element_length(elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> First Order Reliability Method (FORM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1654664813824,
     "user": {
      "displayName": "Christos Lathourakis",
      "userId": "10659327587245285172"
     },
     "user_tz": -120
    },
    "id": "5gyYATYAnfti"
   },
   "outputs": [],
   "source": [
    "def FORM_geom(g, distr):\n",
    "    # initial check if there exists a Nataf object\n",
    "    if not (isinstance(distr, ERANataf)):\n",
    "        raise RuntimeError(\"Incorrect distribution. Please create an ERANataf object!\")\n",
    "\n",
    "    d = len(distr.Marginals)\n",
    "\n",
    "    # objective function\n",
    "    dist_fun = lambda u: np.linalg.norm(u)\n",
    "\n",
    "    # parameters of the minimize function\n",
    "    u0 = 0.1 * np.ones(d)  # initial search point\n",
    "\n",
    "    # nonlinear constraint: H(u) <= 0\n",
    "    H = lambda u: g(distr.U2X(u))\n",
    "    cons = {\"type\": \"ineq\", \"fun\": lambda u: -H(u)}\n",
    "\n",
    "    # method for minimization\n",
    "    alg = \"SLSQP\"\n",
    "\n",
    "    # use constraint minimization\n",
    "    res = sp.optimize.minimize(dist_fun, u0, constraints=cons, method=alg)\n",
    "\n",
    "    # unpack results\n",
    "    u_star = res.x\n",
    "    beta = res.fun\n",
    "    if np.all(u_star < 0):\n",
    "        beta *= -1\n",
    "\n",
    "    # compute design point in orignal space and failure probability\n",
    "    Pf = sp.stats.norm.cdf(-beta)\n",
    "\n",
    "    return Pf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-DSdg8EbBGW"
   },
   "source": [
    "<h3> Custom Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1654664814309,
     "user": {
      "displayName": "Christos Lathourakis",
      "userId": "10659327587245285172"
     },
     "user_tz": -120
    },
    "id": "q-0Ab6XJbBGd"
   },
   "outputs": [],
   "source": [
    "fixed_obs = [\n",
    "        [0.00852848, 0.02275248, 0.03127091, 0.00761781, 0.01913262, 0.03741704], \n",
    "        [0.0080204, 0.02363802, 0.03252855, 0.00832495, 0.02148896, 0.03863805],\n",
    "        [0.00903002, 0.02576496, 0.03592601, 0.00835177, 0.0233659, 0.03142951]\n",
    "    ]\n",
    "\n",
    "class frameEnv(Env):\n",
    "    def __init__(self, noise, muA, muB, numSteps = 20, u=0.4/0.075**2, \n",
    "                 coeffVarA=0.5, coeffVarB=0.2, costReplace=10000, driftThres=0.024):\n",
    "\n",
    "        self.model = FEModel()\n",
    "\n",
    "        self.noise = noise\n",
    "        self.muA = muA\n",
    "        self.sigmaA = self.muA * coeffVarA\n",
    "        self.muB = muB\n",
    "        self.sigmaB = self.muB * coeffVarB\n",
    "        self.u = u # the scale of the Gamma distributions\n",
    "        self.R = np.eye(self.model.numCols) # correlation matrix for Nataf transformation\n",
    "\n",
    "        self.logMuA = mathlog(self.muA**2/mathsqrt(self.muA**2+self.sigmaA**2))\n",
    "        self.logSigmaA = mathsqrt(mathlog(1+self.sigmaA**2/self.muA**2))\n",
    " \n",
    "        self.numSteps = numSteps\n",
    "        self.action_space = Discrete(self.model.numCols * 3) # 0: do nothing, 1: repair, 2: replace\n",
    "        self.observation_space = Box(-np.inf, np.inf, shape=(self.model.numCols * 2,), dtype=np.float32) \n",
    "        self.obs = []\n",
    "        \n",
    "        # Costs\n",
    "        self.costReplace = -1 * costReplace\n",
    "        self.costRepair = 0.5 * self.costReplace\n",
    "        self.costFailure = self.model.numCols * self.costReplace\n",
    "\n",
    "        self.failThres = driftThres\n",
    "\n",
    "        # Reset the environment\n",
    "        self.reset()\n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        repairInds = action == 1 # the indices of the components that are being repaired\n",
    "        replaceInds = action == 2 # the indices of the components that are being replaced\n",
    "\n",
    "        self.ages[repairInds] = np.clip(self.ages[repairInds] - 2, a_min=0, a_max=None) # subtract 2 age steps for all components being repaired\n",
    "        self.ages[replaceInds] = 0 # reset the ages of the replaced components\n",
    "        self.shapes[replaceInds] = 0 # reset the shapes of the Gamma distribution of the damage for the replaced components\n",
    "\n",
    "        # Bayesian inference\n",
    "        # Updating the distributions of A, B\n",
    "        self._bayesian_inference()\n",
    "\n",
    "        reward = self._calc_pf_FORM() * self.costFailure + repairInds.sum() * self.costRepair + replaceInds.sum() * self.costReplace\n",
    "\n",
    "        self.ages += 1\n",
    "        self.decisionStep += 1\n",
    "        \n",
    "        done = True if self.decisionStep == self.numSteps else False\n",
    "        info = {}\n",
    "\n",
    "        return np.concatenate((self.shapes, self.ages)), reward, done, info\n",
    "    \n",
    "\n",
    "    def _bayesian_inference(self, draws=4000, tune=2000, targetAccept=0.9):\n",
    "        \"\"\"\n",
    "        Performs the Bayesian Inference, i.e. updates the distributions of parameters A, B, \n",
    "        using the damage increments that are obtained using a Gamma process\n",
    "        \"\"\"\n",
    "        with pm.Model() as bayesianInference:\n",
    "\n",
    "            if self.decisionStep == 0:\n",
    "                A = pm.Lognormal('A', mu=self.logMuA, sigma=self.logSigmaA)\n",
    "                B = pm.Normal('B', mu=self.muB, sigma=self.sigmaB)\n",
    "            else:\n",
    "                A = self._from_posterior('A', self.trace['A'])\n",
    "                B = self._from_posterior('B', self.trace['B'])\n",
    "                \n",
    "            # Sample a ann b for the components' damage increment distributions\n",
    "            a = A.random(size=(self.model.numCols))\n",
    "            b = B.random(size=(self.model.numCols))\n",
    "\n",
    "            self.shapes += a * (self.ages + 1) ** b - a * self.ages ** b\n",
    "\n",
    "            # create the continuous RV which is the expected value for the model\n",
    "            damages = np.random.gamma(shape=self.shapes, scale=1/self.u, size=(5, self.model.numCols))\n",
    "\n",
    "            modalDispls = np.mean(np.abs(np.array([self.model.eigen_analysis(dams) for dams in damages])), axis=0)\n",
    "\n",
    "            obsMus = np.abs(self.model.eigen_analysis(np.random.gamma(shape=self.shapes, scale=1/self.u)))\n",
    "\n",
    "            noises = obsMus * self.noise\n",
    "            \n",
    "            eigObs = np.random.normal(loc=obsMus, scale=noises)\n",
    "            self.obs.append(eigObs.reshape((-1, 1)))\n",
    "            \n",
    "            obsModalDispls = pm.Normal('observed', mu=modalDispls.reshape((-1, 1)), sigma=noises.reshape((-1, 1)), observed=fixed_obs[self.decisionStep])\n",
    "\n",
    "            self.trace = pm.sample(init='adapt_diag', progressbar=False)\n",
    "\n",
    "    def _from_posterior(self, param, samples):\n",
    "        \"\"\"\n",
    "        Transforms the posterior distributions to priors for the next iteration inference\n",
    "        \n",
    "        Parameters:\n",
    "        param (str): RV name\n",
    "        samples (ndarray) : Posterior discrete values (bins)\n",
    "        \n",
    "        Returns:\n",
    "        pymc3.model.TransformedRV : Continuous distribution to be used as prior\n",
    "  \n",
    "        \"\"\"\n",
    "        smin, smax = np.min(samples), np.max(samples)\n",
    "        x = np.linspace(smin, smax, 100)\n",
    "        y = stats.gaussian_kde(samples)(x)\n",
    "\n",
    "        return pm.distributions.Interpolated(param, x, y)   \n",
    "\n",
    "    def _calc_pf_MC(self, pfIters=5000): # Damages is an 1D numpy array containing the samples that were generated through NUTS\n",
    "        damsPf = np.random.gamma(shape=self.shapes, scale=1/self.u, size=(pfIters, self.model.numCols))\n",
    "        driftsPf = np.array([self.model.linear_static_analysis(ds) for ds in damsPf])\n",
    "\n",
    "        return (driftsPf > self.failThres).sum() / pfIters\n",
    "    \n",
    "    def _calc_pf_FORM(self):\n",
    "\n",
    "        pi_pdf = [ERADist('gamma', 'PAR', [self.u, sh]) for sh in self.shapes]\n",
    "        pi_pdf = ERANataf(pi_pdf, self.R)\n",
    "        g = lambda dams: np.abs(self.failThres - self.model.linear_static_analysis(np.array(dams)))\n",
    "        pf = FORM_geom(g, pi_pdf)\n",
    "\n",
    "        return pf\n",
    "\n",
    "    def reset(self):\n",
    "        self.decisionStep = 0\n",
    "        self._new_struct()\n",
    "\n",
    "        return np.concatenate((self.shapes, self.ages))\n",
    "    \n",
    "    def _new_struct(self):\n",
    "        self.ages = np.zeros((self.model.numCols,))\n",
    "        self.shapes = np.zeros((self.model.numCols,))\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35pXfoxNbBG_"
   },
   "source": [
    "<h4> Problem Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1654664816899,
     "user": {
      "displayName": "Christos Lathourakis",
      "userId": "10659327587245285172"
     },
     "user_tz": -120
    },
    "id": "IOz2zi1hbBHA"
   },
   "outputs": [],
   "source": [
    "muA = 0.5\n",
    "muB = 2.5\n",
    "\n",
    "noise = 0.1 # coefficient of variation, meaning that sigma = omegaNoise * mu\n",
    "\n",
    "env = frameEnv(noise, muA, muB, numSteps = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Episode run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5283524,
     "status": "ok",
     "timestamp": 1654670109559,
     "user": {
      "displayName": "Christos Lathourakis",
      "userId": "10659327587245285172"
     },
     "user_tz": -120
    },
    "id": "6nhbzG6PbBHE",
    "outputId": "738500b0-9755-47b2-a2d8-e0e4c7936f69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for decision step 1 is completed\n",
      "Inference for decision step 2 is completed\n",
      "Inference for decision step 3 is completed\n",
      "Episode ran successfully\n"
     ]
    }
   ],
   "source": [
    "observation, totalReward, done = env.reset(), 0, False\n",
    "\n",
    "while not done:\n",
    "\n",
    "    # Actions were chosen by the DRL agent\n",
    "    # To display only the inference part, they are chosen at random\n",
    "    action = np.random.choice([0, 1, 2], size=(6,))\n",
    "    \n",
    "    # Can not ensure that no assertion error will occur\n",
    "    # In the complete script the code would just continue with the next episode\n",
    "    try:\n",
    "        state_, reward, done, _ = env.step(action)\n",
    "    except AssertionError:\n",
    "        print(\"Assertion Error during sampling\")\n",
    "\n",
    "    totalReward += reward\n",
    "    state = state_\n",
    "\n",
    "    print(f\"Inference for decision step {env.decisionStep} is completed\")\n",
    "\n",
    "print(\"Episode ran successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.29928656e-03, 1.01671861e-02, 3.50965657e-03, 2.15941788e-03,\n",
       "        2.95776877e-03, 1.12232343e-02],\n",
       "       [1.24671696e-06, 3.30556876e-03, 1.01396507e-02, 2.64947230e-02,\n",
       "        6.01483045e-03, 1.61973640e-05],\n",
       "       [5.23385643e-05, 2.05113514e-02, 1.03133093e-02, 2.94321031e-03,\n",
       "        1.17115403e-02, 2.65246943e-04],\n",
       "       [1.18137616e-02, 3.31831088e-03, 2.63230033e-02, 1.06722011e-02,\n",
       "        1.33265821e-03, 9.53738781e-04],\n",
       "       [7.47007588e-03, 7.66191272e-03, 2.33507167e-02, 7.66272132e-02,\n",
       "        9.57462661e-03, 1.14261975e-04]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.gamma(shape=env.shapes, scale=1/env.u, size=(5, env.model.numCols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>The loop above corresponds to just a single (1) episode. In order for the DRL (PPO) agent to learn the optimal policy, thousands of episodes need to be ran, making the inference runtime a crucial feature to improve."
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "PPO_center.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "d181997f5920050c428f47b4e0d4ca307f3989efe9a868292a4fb0c9fdb4a0fb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
